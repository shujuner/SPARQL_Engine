### 该项目已经被构建一年多，最近重新整理项目内容，因而进行了大量的删除和重新上传工作###

## ***SPARQL_Engine***
随着RDF数据量的增长，索引和查询大型数据集的变得非常困难。许多分布式SPARQL查询引擎被提出。它们利用无共享计算集群，或者构建在分布式数据处理框架(如MapReduce)上, 或者实现专有的分布式计算方法。它们将RDF图划分到多台机器中来并行化查询执行时间以减少运行时间。回答查询通常涉及在每个节点上处理本地数据，并在节点之间交换数据。

一些SPARQL引擎。
1.	HadoopRDF: 一种基于垂直分区思想的SPARQL引擎。HadoopRDF在HDFS上使用多个文件存储数据，每个谓词对应于一个文件，还基于显式和隐式类型信息将每个谓词文件分割为多个更小的文件。HadoopRDF以MapReduce迭代序列的形式执行查询，基于查询优化器选择最小化MapReduce迭代次数和中间结果大小的最优查询计划。 

2.	S2RDF: 基于Spark的SPARQL引擎，它提出了一种用于RDF数据的关系分区技术，称为扩展垂直分区(ExtVP)。ExtVP使用半连接约化来最小化数据偏差，并消除不参与任何连接的悬浮三元组。对于任意两个垂直分区，ExtVP预计算连接缩减，结果在HDFS中物化为具体的存储表。S2RDF不直接在Spark上运行，它将SPARQL查询转换为SQL作业，然后使用Spark SQL进行执行。

3.	SparkRDF:基于Spark的SPARQL引擎。它使用哈希分区将图分布到多层弹性子图(MESG)中。MESG是基于类和关系来减少搜索空间与内存开销的。在SparkRDF中创建了五种索引，用于建模RDSGs(弹性离散子图)。对于查询处理，SparkRDF使用Spark api和迭代连接操作来最小化中间结果，以执行子图匹配。

4.	S2X利用RDF数据内在的图结构，将SPARQL查询作为基于图的计算在GraphX上进行处理。它使用并行的顶点中心模型来执行SPARQL的BGP匹配，而其他的操作符，如可选和过滤，则通过Spark-RDD操作符进行处理。S2X使用两种字符串编码类型:散列和基于计数的编码。基于哈希的编码使用64位哈希函数对主体和对象进行编码，而基于计数的编码则为它们分配唯一的数值。S2X没有特殊的RDF分区器，它使用GraphX散列来将输入图在工作节点之间进行分区。

5.	SPARQLGX以垂直分区的方式将RDF数据存储在HDFS中，具有快速转换、压缩存储和轻量级索引等优点。查询时基于VP表以及一些统计信息，将SPARQL查询转化为可执行的scala代码。

6.	TriAD使用基于主语和宾语的轻量级散列分区，对数据具有局部性感知，并可以在没有通信的情况下处理大量并发连接。它在每台机器上创建6个内存表(SPO,SOP,PSO,OSP,OPS,POS)。在不同的机器之间对这些索引进行散列分区，并且按照字典顺序在每台机器上进行排序。这使得TriAD能够在不同的SPO索引上执行高效的分布式合并连接。多个连接操作由所有工作节点并发执行，这些节点通过异步消息传递进行通信。

7.	AdPart使用自适应的工作负载感知扩展了AdPart-NA系统，以应对动态的RDF工作负载。它监视查询工作负载，并增量的重新分配经常被访问的部分数据。通过维护这些模式，许多未来查询都可以在不进行通信的情况下进行评估。AdPart的自适应性使得其查询可以受益于基于散列的数据局部性。

8.	gStoreD是一个与分区无关的分布式系统，它不会分解输入查询，而是将其原样发送到工作节点。gStoreD通过计算每个工作节点上的部分局部匹配来开始执行查询，这个过程依赖于单机版gStore。然后，gStoreD组装局部匹配结果以生成跨分区结果。其允许两种组装模式：集中式和分布式。集中式组装模式将局部结果发送到一个集中式站点；而分布式模式则在多个站点中并行的组装它们。
